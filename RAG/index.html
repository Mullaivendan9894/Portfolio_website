<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Generative AI Project: RAG-based Conversational Assistant</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      line-height: 1.6;
      margin: 0;
      padding: 0;
      background-color: #f9f9f9;
      color: #333;
    }
    header {
      background-color: #007BFF;
      color: white;
      padding: 40px 20px;
      text-align: center;
    }
    h1 {
      font-size: 2.5rem;
      margin: 0;
    }
    h2, h3 {
      color: #007BFF;
    }
    .container {
      max-width: 1200px;
      margin: 0 auto;
      padding: 0 20px;
      background-color: white;
      box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
    }
    img {
      max-width: 70%;
      height: auto;
      display: block;
      margin: 20px auto;
      border: 1px solid #ddd;
      border-radius: 4px;
    }
    .caption {
      font-style: italic;
      text-align: center;
      color: #555;
      margin-top: 5px;
    }
    .section {
      margin-bottom: 40px;
    }
    .section h2 {
      border-bottom: 2px solid #007BFF;
      padding-bottom: 10px;
      text-align: center;
    }
    .section p {
      text-align: justify;
    }
    .features, .technologies {
      display: flex;
      flex-wrap: wrap;
      gap: 20px;
      margin-top: 20px;
    }
    .features div, .technologies div {
      background-color: #ffffff;
      padding: 15px;
      border-radius: 5px;
      flex: 1 1 calc(33.333% - 40px);
      box-shadow: 0 0 5px rgba(0, 0, 0, 0.1);
    }
    footer {
      text-align: center;
      padding: 20px;
      background-color: #007BFF;
      color: white;
      margin-top: 40px;
    }
    pre {
      background-color: #f4f4f4;
      padding: 10px;
      border-radius: 5px;
      overflow-x: auto;
    }
    code {
      font-family: Consolas, monospace;
      color: #007BFF;
    }
    .methodology-steps {
      display: block;
    }
    .methodology-steps div {
      background-color: #ffffff;
      padding: 15px;
      border-radius: 5px;
      margin-bottom: 20px;
      box-shadow: 0 0 5px rgba(0, 0, 0, 0.1);
    }
    .markdown-response {
      background-color: #f9f9f9;
      padding: 20px;
      border-radius: 5px;
      border: 1px solid #ddd;
    }
    .markdown-response h3 {
      color: #007BFF;
      margin-top: 0;
    }
    .markdown-response ul {
      list-style-type: disc;
      padding-left: 20px;
    }
    .markdown-response ul li {
      margin-bottom: 10px;
    }
  </style>
</head>
<body>
  <header>
    <h1>Generative AI Project: RAG-based Conversational Assistant</h1>
    <p>Retrieval-Augmented Generation (RAG) for Standards and Design Guidelines</p>
  </header>

  <div class="container">
    <!-- Project Overview -->
    <section class="section">
      <h2>Project Overview</h2>
      <p>
        This project implements a <strong>Retrieval-Augmented Generation (RAG)</strong> conversational assistant designed to query standards and design guidelines. The system leverages advanced AI models, including <strong>Groq's Llama-3.3-70b-Specdec</strong> for response generation and <strong>HuggingFace's sentence-transformers/all-MiniLM-L6-v2</strong> for document embeddings. The system processes uploaded documents, such as the <strong>Ernst Neufert ARCHITECTS' DATA</strong> PDF, stores them in a <strong>FAISS vector database</strong>, and provides context-aware responses using a chat history-aware RAG pipeline. It is particularly useful for professionals in fields like <strong>architecture and engineering</strong> who need quick access to detailed design standards and guidelines.
      </p>
      <img src="images/rag_pipeline_diagram.png" alt="RAG Pipeline Diagram">
      <p class="caption">Figure 1: RAG Pipeline Diagram - Overview of the Retrieval-Augmented Generation process.</p>
    </section>

    <!-- Key Features -->
    <section class="section">
      <h2>Key Features</h2>
      <div class="features">
        <div>
          <h3>RAG Pipeline</h3>
          <p>Combines document retrieval and language generation for accurate, context-aware responses.</p>
        </div>
        <div>
          <h3>Document Processing</h3>
          <p>Handles PDF documents, extracts text, and splits them into manageable chunks for efficient retrieval.</p>
        </div>
        <div>
          <h3>Chat History Integration</h3>
          <p>Maintains session-based chat history for personalized and context-aware interactions.</p>
        </div>
        <div>
          <h3>Vector Database</h3>
          <p>Uses <strong>FAISS</strong> for fast and efficient similarity search over document embeddings.</p>
        </div>
        <div>
          <h3>Streamlit Web Application</h3>
          <p>Provides a user-friendly interface for uploading documents and interacting with the chatbot.</p>
        </div>
      </div>
    </section>

    <!-- Technologies Used -->
    <section class="section">
      <h2>Technologies Used</h2>
      <div class="technologies">
        <div>
          <h3>Language Model</h3>
          <p>Groq Llama-3.3-70b-Specdec</p>
        </div>
        <div>
          <h3>Embedding Model</h3>
          <p>HuggingFace sentence-transformers/all-MiniLM-L6-v2</p>
        </div>
        <div>
          <h3>Vector Database</h3>
          <p>FAISS</p>
        </div>
        <div>
          <h3>Libraries</h3>
          <p>LangChain, Streamlit, PyPDFDirectoryLoader, HuggingFace Embeddings</p>
        </div>
        <div>
          <h3>Programming Language</h3>
          <p>Python</p>
        </div>
      </div>
    </section>

    <!-- Methodology -->
    <section class="section">
      <h2>Methodology</h2>
      <p>
        The project follows a structured pipeline to process documents, generate embeddings, and provide context-aware responses. Here’s a step-by-step breakdown:
      </p>
      <div class="methodology-steps">
        <div>
          <h3>1. Load PDF Documents</h3>
          <p><strong>Purpose:</strong> Extract text from PDF documents for further processing.</p>
          <p><strong>Explanation:</strong> The <code>PyPDFDirectoryLoader</code> is used to load and extract text from all PDFs in a specified directory.</p>
          <img src="images/load.png" alt="Document Processing">
          <p class="caption">Figure 2: Document Processing - Loading the PDF documents.</p>
        </div>
        <div>
          <h3>2. Initialize Groq LLM</h3>
          <p><strong>Purpose:</strong> Use the Groq language model for generating responses.</p>
          <p><strong>Explanation:</strong> The Groq LLM is configured with an API key to enable communication with the model.</p>
          <pre><code>
from langchain_groq import ChatGroq
llm = ChatGroq(model = "Llama-3.3-70b-Specdec", groq_api_key = groq_api_key)
          </code></pre>
        </div>
        <div>
          <h3>3. Initialize Embeddings</h3>
          <p><strong>Purpose:</strong> Convert textual data into numerical vectors for similarity-based retrieval.</p>
          <p><strong>Explanation:</strong> The <code>sentence-transformers/all-MiniLM-L6-v2</code> model is used to generate embeddings for the documents.</p>
          <pre><code>
from langchain_huggingface.embeddings import HuggingFaceEmbeddings
embeddings = HuggingFaceEmbeddings(model_name ="sentence-transformers/all-MiniLM-L6-v2")
          </code></pre>
        </div>
        <div>
          <h3>4. Split Documents</h3>
          <p><strong>Purpose:</strong> Split large documents into smaller chunks for better retrieval accuracy.</p>
          <p><strong>Explanation:</strong> The <code>RecursiveCharacterTextSplitter</code> creates chunks with overlap to ensure context continuity.</p>
          <img src="images/split.png" alt="Document Splitting">
          <p class="caption">Figure 3: Document Splitting - Splitting documents into smaller chunks.</p>
        </div>
        <div>
          <h3>5. Embeddings</h3>
          <p><strong>Purpose:</strong> Convert textual data into numerical vectors for similarity-based retrieval.</p>
          <p><strong>Explanation:</strong> The <code>sentence-transformers/all-MiniLM-L6-v2</code> model is used to generate embeddings for the documents.</p>
          <img src="images/emb.png" alt="Embeddings Visualization">
          <p class="caption">Figure 4: Embeddings Visualization - Converting text into numerical vectors.</p>
        </div>
        <div>
          <h3>6. Use FAISS for Vector Storage</h3>
          <p><strong>Purpose:</strong> Store document embeddings in a vector database for efficient retrieval.</p>
          <p><strong>Explanation:</strong> FAISS is a fast similarity search library that indexes and retrieves vectors.</p>
          <img src="images/store.png" alt="FAISS Vector Database">
          <p class="caption">Figure 5: FAISS Vector Database - Storing and retrieving document embeddings.</p>
        </div>
        <div>
          <h3>7. Create Prompt Templates</h3>
          <p><strong>Purpose:</strong> Define reusable prompt templates for guiding the LLM in generating responses.</p>
          <p><strong>Explanation:</strong> Prompts are designed to reformulate questions based on chat history and provide detailed answers.</p>
          <pre><code>
## contextualize_question_system_prompt
contextualize_question_system_prompt = (
    "Based on the chat history and the most recent user question, "
    "which may refer to previous context in the conversation, "
    "reformulate the question so it can be understood independently of the chat history. "
    "Do not provide an answer; simply rephrase the question if necessary, otherwise return it unchanged."
)

contextualize_question_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", contextualize_question_system_prompt),
        MessagesPlaceholder("chat_history"),
        ("human", "{input}")
    ]
)

## System prompt
system_prompt = (
    "You are a highly knowledgeable assistant tasked with providing accurate answers to questions."
    "Utilize the given pieces of retrieved information to craft your response."
    "If the answer is not present in the provided context, indicate that you do not know."
    "Your responses should be detailed and comprehensive."
    "\n\n"
    "{context}"
)

question_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", system_prompt),
        MessagesPlaceholder("chat_history"),
        ("human", "{input}")
    ]
)
          </code></pre>
        </div>
        <div>
          <h3>8. Create Retriever and History-Aware Retriever</h3>
          <p><strong>Purpose:</strong> Build a retriever that considers chat history when retrieving documents.</p>
          <p><strong>Explanation:</strong> The retriever ensures relevance by reformulating queries based on chat history.</p>
          <pre><code>
from langchain.chains import create_history_aware_retriever, create_retrieval_chain
history_aware_retriever = create_history_aware_retriever(llm, retriever, contextualize_question_prompt)
          </code></pre>
          <img src="images/History aware retriver.png" alt="Retriever Flowchart">
          <p class="caption">Figure 6: Retriever Flowchart - Integration of the retriever with chat history.</p>
        </div>
        <div>
          <h3>9. Combine Documents</h3>
          <p><strong>Purpose:</strong> Organize retrieved chunks into a coherent structure for answering questions.</p>
          <p><strong>Explanation:</strong> The <code>create_stuff_documents_chain</code> function combines retrieved documents for processing by the LLM.</p>
          <pre><code>
from langchain.chains.combine_documents import create_stuff_documents_chain
question_answer_chain = create_stuff_documents_chain(llm, question_prompt)
          </code></pre>
        </div>
        <div>
          <h3>10. Create Retriever Chain</h3>
          <p><strong>Purpose:</strong> Link the retriever and document combiner into a RAG pipeline.</p>
          <p><strong>Explanation:</strong> The retrieval chain integrates retrieval and answer generation.</p>
          <pre><code>
from langchain.chains import create_retrieval_chain
rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)
          </code></pre>
        </div>
        <div>
          <h3>11. Manage Chat History</h3>
          <p><strong>Purpose:</strong> Maintain session-based chat history for context retention.</p>
          <p><strong>Explanation:</strong> The <code>ChatMessageHistory</code> class stores interactions by session ID.</p>
          <pre><code>
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory

store = {}

def get_session_history(session_id: str) -> BaseChatMessageHistory:
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]
          </code></pre>
        </div>
        <div>
          <h3>12. Add Runnable with Message History</h3>
          <p><strong>Purpose:</strong> Integrate the RAG chain with message history for conversational capabilities.</p>
          <p><strong>Explanation:</strong> The <code>RunnableWithMessageHistory</code> class enables history-aware responses.</p>
          <pre><code>
from langchain_core.runnables.history import RunnableWithMessageHistory
conversational_rag_chain = RunnableWithMessageHistory(
    rag_chain,
    get_session_history,
    input_messages_key = "input",
    history_messages_key = "chat_history",
    output_messages_key = "answer"
)
          </code></pre>
        </div>
      </div>
    </section>

    <!-- Sample Invocation -->
    <section class="section">
      <h2>Sample Invocation</h2>
      <p>
        The system can be queried with questions related to design standards. For example:
      </p>
      <pre><code>
Question: "What are the components and design standards with dimensions I should follow when designing hospital special units?"
      </code></pre>
      <div class="markdown-response">
        <h3>Response:</h3>
        <p>
          Designing hospital special units requires careful consideration of various components and design standards to ensure efficient and effective patient care. Here's a detailed overview of the key components and design standards with dimensions to follow:
        </p>
        <h3>1. Intensive Care Units (ICUs):</h3>
        <ul>
          <li><strong>Bed unit basic space module:</strong> 11-15 m²/unit</li>
          <li><strong>Number of beds:</strong> 6-7 maximum per unit</li>
          <li><strong>Distance from control station or viewpoint to patient:</strong> Minimal, so that equipment can be read and patient can be seen.</li>
          <li><strong>Nurse/physician station:</strong> 4-10 m²</li>
          <li><strong>Support area for medication station, utility, and treatment:</strong> 11-15 m²</li>
          <li><strong>Amenities such as rest room, locker, and WC:</strong> 0.5-1.0 m² per bed</li>
          <li><strong>Design considerations:</strong>
            <ul>
              <li>Will the patient be conscious, require privacy, toilet, or constant nursing attention?</li>
              <li>Will the location or configuration of the unit help or hinder the patient's recovery?</li>
              <li>Can staff see all patients easily? Is the ratio of patients to staff station appropriate?</li>
            </ul>
          </li>
        </ul>
        <h3>2. Neurosurgical Units:</h3>
        <ul>
          <li><strong>Ratio of population to beds:</strong> 1:100,000</li>
          <li><strong>Number of beds:</strong> 20-30 per unit</li>
          <li><strong>Operating theaters:</strong> 2-3 per unit, with a minimum size of 40-50 m² each</li>
          <li><strong>Design considerations:</strong>
            <ul>
              <li>Patients will be unconscious during surgery, requiring constant monitoring and life-support equipment.</li>
              <li>Staff will require easy access to patients, equipment, and support services.</li>
              <li>Infection control and separation of patients from noise are crucial.</li>
            </ul>
          </li>
        </ul>
        <h3>3. Spinal Injury Units:</h3>
        <ul>
          <li><strong>Number of beds:</strong> 20-24 for stages 1 and 2, 28-32 for stage 3</li>
          <li><strong>Bed width:</strong> 1,000 mm (wider than normal)</li>
          <li><strong>Bed center distance:</strong> 3,500 mm</li>
          <li><strong>Nurse working room:</strong> Similar to that for physical/mental handicapped units</li>
          <li><strong>Design considerations:</strong>
            <ul>
              <li>Patients will require 100% care, with nearly always doubly incontinent and aggressive towards staff and visitors.</li>
              <li>Occupational therapy, physiotherapy, and study form vital parts of rehabilitation.</li>
              <li>Patients may take months to recover, requiring a phased approach to care.</li>
            </ul>
          </li>
        </ul>
        <h3>4. Ward Design: General</h3>
        <ul>
          <li><strong>Outlooks on ward sizes:</strong> Subject to rapid change, with a trend away from classical ward types (e.g., 'Nightingale' and 'Rigs').</li>
          <li><strong>Preference for 2-4 bed wards:</strong> Despite controversy surrounding very small wards.</li>
          <li><strong>Design considerations:</strong>
            <ul>
              <li>Patients need audio and visual privacy during medical visits.</li>
              <li>Background noise and bed curtains can provide some privacy, but lights can disturb at night.</li>
              <li>Small wards can be peaceful for resting patients, but may not provide audio-privacy.</li>
            </ul>
          </li>
        </ul>
        <h3>5. Acute Ward Design:</h3>
        <ul>
          <li><strong>Number of beds:</strong> 24-30 per ward</li>
          <li><strong>Breakdown of bed areas:</strong>
            <ul>
              <li>3 x 8-B rooms + 4 x 1-B rooms</li>
              <li>4 x 6-B rooms + 4 x 1-B rooms</li>
              <li>2 x 12-B rooms + 4 x 1-B rooms</li>
            </ul>
          </li>
          <li><strong>Design considerations:</strong>
            <ul>
              <li>Walking distance: Keep short for nurses and ambulant patients.</li>
              <li>Observation: 50% of beds should be visible from the nurse station.</li>
              <li>Control: Patients, particularly children, adolescents, and confused, need to be controlled.</li>
              <li>Noise: Design for 40-45 dB by day and 35-40 dB at night in multi-B wards.</li>
            </ul>
          </li>
        </ul>
        <h3>6. Acute Ward Areas:</h3>
        <ul>
          <li><strong>1-B room:</strong> 9.3-10.0 m²</li>
          <li><strong>Multi-B bay (per bed):</strong> 0.75 m²</li>
          <li><strong>Day room (per bed):</strong> 0.5-1.0 m²</li>
          <li><strong>Lockers, etc. (per bed):</strong> 0.5-1.0 m²</li>
          <li><strong>Nurse station:</strong> 4.0-10.0 m²</li>
          <li><strong>Clean utility:</strong> 10.2-18.0 m²</li>
          <li><strong>Dirty utility and sluice:</strong> 14.0-16.0 m²</li>
          <li><strong>Treatment room:</strong> 10.25-12.0 m²</li>
          <li><strong>Assisted bathroom:</strong> 7.0-9.0 m²</li>
          <li><strong>Sisters' room:</strong> 7.0-9.0 m²</li>
          <li><strong>Doctors' room:</strong> 7.0-9.0 m²</li>
          <li><strong>Bathroom:</strong> 7.0 m²</li>
          <li><strong>WC with hand rinse basin:</strong> 2.75 m²</li>
          <li><strong>Ward kitchen:</strong> 20.0 m²</li>
          <li><strong>Flower bay:</strong> 2.0-2.5 m²</li>
          <li><strong>Circulation area:</strong> 5.0-8.0 m²</li>
        </ul>
        <h3>7. Mechanical and Electrical Services:</h3>
        <ul>
          <li><strong>Mechanical ventilation:</strong> Often noisy and unsatisfactory, full air-conditioning expensive to install and run.</li>
          <li><strong>Natural ventilation:</strong> Rely on for normal sites, away from air or traffic noise.</li>
          <li><strong>Central work rooms:</strong> Require mechanical ventilation and suffer from heat build-up in summer.</li>
          <li><strong>Electrical services:</strong> Ensure sufficient power and data points for equipment and staff.</li>
        </ul>
        <h3>8. Infection Control:</h3>
        <ul>
          <li><strong>Design considerations:</strong>
            <ul>
              <li>Patients will be unconscious during surgery, requiring constant monitoring and life-support equipment.</li>
              <li>Staff will require easy access to patients, equipment, and support services.</li>
              <li>Separation of patients from noise and infection control are crucial.</li>
            </ul>
          </li>
          <li><strong>Measures:</strong>
            <ul>
              <li>Anti-static flooring and flashproof electrical outlets.</li>
              <li>Isolation rooms for infectious patients.</li>
              <li>Easy-to-clean surfaces and equipment.</li>
            </ul>
          </li>
        </ul>
        <h3>9. Fire Safety:</h3>
        <ul>
          <li><strong>Design considerations:</strong>
            <ul>
              <li>Fire-resistant materials and construction.</li>
              <li>Compartmentalization of wards and departments.</li>
              <li>Fire alarms, sprinkler systems, and smoke detectors.</li>
              <li>Emergency evacuation plans and routes.</li>
            </ul>
          </li>
        </ul>
        <h3>10. Accessibility:</h3>
        <ul>
          <li><strong>Design considerations:</strong>
            <ul>
              <li>Wheelchair accessibility: Minimum 1,200 mm wide corridors and doorways.</li>
              <li>Ramp gradients: 1:12 for easy access.</li>
              <li>Elevators: Minimum 1,500 mm wide and 2,100 mm deep.</li>
              <li>Toilets: Wheelchair-accessible, with emergency alarms and grab bars.</li>
            </ul>
          </li>
        </ul>
        <p>
          These are some of the key components and design standards to follow when designing hospital special units. Remember to consult local building codes, regulations, and healthcare authorities for specific requirements and guidelines.
        </p>
      </div>
    </section>

    <!-- Streamlit Web Application -->
    <section class="section">
      <h2>Streamlit Web Application</h2>
      <p>
        The project includes a <strong>Streamlit-based web application</strong> that allows users to:
      </p>
      <ul>
        <li>Upload PDF documents.</li>
        <li>Enter a Groq API key.</li>
        <li>Interact with the chatbot using a chat interface.</li>
        <li>View chat history and responses.</li>
      </ul>
      <img src="images/streamlit_1.png" alt="Streamlit Web Application">
      <p class="caption">Figure 7: Streamlit Web Application - User interface for interacting with the chatbot.</p>
    </section>

    <!-- Conclusion -->
    <section class="section">
      <h2>Conclusion</h2>
      <p>
        This project demonstrates the power of <strong>Retrieval-Augmented Generation (RAG)</strong> in building a conversational assistant for querying complex documents like design standards and guidelines. By combining advanced language models, embeddings, and vector databases, the system provides accurate, context-aware responses. Future improvements could include support for additional document formats, integration with cloud storage, and enhanced user interface features.
      </p>
    </section>
  </div>

  <footer>
    <p> </p>
  </footer>
</body>
</html>